{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40002,"status":"ok","timestamp":1668233271140,"user":{"displayName":"Estrella Designer","userId":"13292887714158322572"},"user_tz":-330},"id":"m-gfEaCRXYsQ","outputId":"1058bacb-0067-44de-fd30-580e7da00331"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = \"/content/drive/MyDrive/ColabNotebooks/Data/MTech_Data/Exp6_Myo5_20200221/\"\n","fingers= ['1_fingerspread','2_doubletap','3_wavein', '4_waveout','5_fist']\n","path = \"/content/drive/MyDrive/ColabNotebooks/Data/SmallTrial/Day2/Multiple_PressAndRelease_5Sec/\"\n","fingers = ['1T', '2I', '3M', '4R', '5L']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pnCGoFVXah7M"},"outputs":[],"source":["import pandas\n","import datetime\n","import os\n","import math\n","import glob\n","import  numpy as np\n","from scipy import signal\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import scipy \n","from statsmodels import robust\n","from sklearn.metrics import accuracy_score \n","import cv2\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13957,"status":"ok","timestamp":1668233286743,"user":{"displayName":"Estrella Designer","userId":"13292887714158322572"},"user_tz":-330},"id":"WAqt3I9Ckj9Z","outputId":"2714580a-4a76-4d33-9e25-444fc8dd78c0"},"outputs":[],"source":["import glob\n","import sys\n","import pandas\n","minlen = sys.maxsize\n","maxlen = -sys.maxsize -1\n","path = \"/content/drive/MyDrive/ColabNotebooks/Data/2022_60Trials_InstantPressAndRelease/\"\n","fingers = ['1T', '2I', '3M', '4R', '5L']\n","\n","#print(minlen)\n","for exp in fingers :\n","    files = glob.glob(path + exp + '/emg*.csv')    \n","    #print(files)    \n","    for file in files:\n","        emgData = pandas.read_csv(file)\n","        namepos = file.index('-')\n","        name = file[namepos:]\n","        if (minlen > len(emgData[emgData.columns[0]])):\n","          minlen = len(emgData[emgData.columns[0]])\n","          print(\"name ={} {}\".format(file, minlen))\n","\n","        if (maxlen < len(emgData[emgData.columns[0]])):\n","          maxlen = len(emgData[emgData.columns[0]])\n","          print(\"max name ={} {}\".format(file, maxlen))\n","print(\"min = {}, max={}\".format(minlen, maxlen))\n","#minlen = 500\n","\n","print(minlen)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6992,"status":"ok","timestamp":1668233293728,"user":{"displayName":"Estrella Designer","userId":"13292887714158322572"},"user_tz":-330},"id":"j_S1M0fRZcRA","outputId":"5db14332-f74e-4c87-937a-f21c5d9c088b"},"outputs":[],"source":["import scipy\n","#### Refactored Features\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#path = \"/content/drive/MyDrive/ColabNotebooks/Data/MTech_Data/Exp6_Myo5_20200221/\"\n","#fingers= ['1_fingerspread','2_doubletap','3_wavein', '4_waveout','5_fist']\n","\n","#path = \"/content/drive/MyDrive/ColabNotebooks/Data/MTech_Data/Exp10_5KeyPress_MultipleTimes_20200228/all/\"\n","path = \"/content/drive/MyDrive/ColabNotebooks/Data/2022_60Trials_InstantPressAndRelease/\"\n","fingers = ['1T', '2I', '3M', '4R', '5L']\n","\n","import glob\n","import sys\n","import pandas\n","import math\n","import pandas\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","minFileLength = sys.maxsize\n","for action in fingers :\n","    files = glob.glob(path + action + '/emg*.csv')    \n","    #print(files)    \n","    for file in files:\n","        emgData = pandas.read_csv(file)\n","        namepos = file.index('-')\n","        name = file[namepos:]\n","        if (minFileLength > len(emgData[emgData.columns[0]])):\n","          minFileLength = len(emgData[emgData.columns[0]])\n","          #print(\"name ={} {}\".format(file, minFileLength))\n","#print(minlen)\n","#factoredminlen = 2000\n","#factoredminlen = 500\n","print(minFileLength)\n","input_cols = ['Mean', 'Standard Deviation','Skewness', 'Kurtosis', 'Standard Error',\n","              'Mean Frequency','Median Frequency']\n","index =0 \n","minlen = 100\n","ENABLE_LOGS = False\n","for exp in fingers:\n","    files = glob.glob(path + exp + '/emg*.csv')\n","    result = []    \n","    index = 0    \n","    if ENABLE_LOGS:\n","      print(files)\n","    for trial in files:\n","      if ENABLE_LOGS:\n","        print(trial)\n","      #if index > 0:\n","      #  break      \n","      emgData = pandas.read_csv(trial)      \n","      for data in emgData.columns:        \n","        #if ENABLE_LOGS and (index > 0):\n","        #  break    \n","        if not 'emg2' in data:\n","          continue\n","        complete_emg = emgData[data]\n","        #emg_frame = complete_emg[0:200]#[50:250]\n","        #for instant press release experiment take sample size as complete emg length for each trial\n","        if \"Instant\" in path:\n","          sample_size = len(complete_emg)\n","        else:\n","          sample_size = minlen        \n","        for i in range(0, minFileLength, sample_size):\n","          result.append([])          \n","          emg = complete_emg[i:i+sample_size]\n","          emg = emg.dropna()\n","          emg_frame = emg\n","          \n","          #emg -= np.mean(emg) #skewness and kurtosis do not depends on mean\n","          emg_frame = pandas.to_numeric(emg_frame)\n","          \n","          #mean absolute value sum(x)\n","          mean = np.mean(abs(emg_frame))\n","          result[index].append(mean)\n","          \n","          #Standard Deviation\n","          std = np.std(emg_frame)\n","          result[index].append(std)\n","          \n","          #Skewness - is by taking the mean of the cubes of differences of each point from the mean\n","          #and then dividing it by the cube of the standard deviation. \n","          \n","          skew = scipy.stats.skew(emg_frame, axis=0)\n","          result[index].append(skew)\n","          \n","          #Kurtosis\n","          kurt =scipy.stats.kurtosis(emg_frame,axis=0,fisher=False) \n","          result[index].append(kurt)\n","\n","          #standard error \n","          sem = scipy.stats.sem(emg_frame)\n","          result[index].append(sem)\n","          #n is nearest power of 2 of len(emg)\n","          n= 1024 #256 #4096 #512 #2048 #4096 \n","          sampling_rate = 200\n","          #i/sampling_rate = (i/len(emg_frame))*(len(emg_frame)/sampling_rate)[time varies from 1/200 to 1]\n","\n","          time = np.array([i/sampling_rate for i in range(0, len(emg_frame), 1)])\n","          #plt.plot(time, emg_frame)\n","          #plt.show()\n","          abs_fft = np.absolute(np.fft.fft(emg_frame, n=n))\n","          #avoid zero from fft before log\n","          if 0 in abs_fft:\n","            all_indexes = [a for a in range(len(abs_fft)) if abs_fft[a] == 0]\n","            #to find second min value to replace the 0\n","            abs_fft[all_indexes] = sys.maxsize\n","            #we may set to epsilon(usual flooring value) if second min can be higher\n","            minValue = min(abs_fft)\n","            abs_fft[all_indexes] = minValue\n","            if ENABLE_LOGS:\n","              print(\"Index {}\".format(all_indexes))\n","              for i in all_indexes:\n","                print(\"{} is = to {}\".format(i, abs_fft[i]))\n","\n","          #spectrum has large dynamic range. lot of details in lower power spectral will be lost. \n","          #to make sure dynamic range is properly maintained 20 (since psd is square rooted) *log\n","          log_abs_fft = np.log(abs_fft)\n","          ####Err -inf for few\n","          #shift_fft = np.fft.fftshift(log_abs_fft)\n","          if False:\n","            print(\"Before Shift {}\".format(log_abs_fft))\n","            plt.plot(log_abs_fft)\n","            plt.show()\n","            #print(\"After Shift {}\".format(shift_fft))\n","            #plt.plot(shift_fft)\n","            #plt.show()\n","          \n","          #print(abs_fft)\n","          psd = (1/n)*20*log_abs_fft          \n","          psd_x = np.array([i for i in range (0, n, 1)])\n","          if ENABLE_LOGS:\n","            print(\"Complete PSD\")\n","            plt.plot(psd_x, psd)\n","            plt.show()\n","          \n","          #print(\"First half PSD\")\n","          #plt.plot(psd_x[0:(int)(n/2)], psd[0:(int)(n/2)])\n","          #plt.psd(psd)\n","          #plt.show()\n","          \n","          psd_half = psd[0:(int)(n/2)]\n","          #print(\"Half {}\".format(len(psd_half)))\n","          #print(psd_half)\n","          #Mean frequency sum(P)/M\n","          sumofpsd = np.sum(psd_half)    \n","          psd_half_pdf = psd_half/sumofpsd\n","          sumofpdf = np.sum(psd_half_pdf)\n","          \n","          if ENABLE_LOGS:\n","            plt.plot(psd_x[0:len(psd_half)], psd_half_pdf)\n","            plt.show()\n","            print(sumofpdf)\n","          \n","          arr_i = [i for i in range(0, len(psd_half),1)]\n","          e_i = psd_half_pdf\n","          e_sum = 0\n","          for t in range (0,len(psd_half),1):\n","            e_sum = e_sum + e_i[t]*arr_i[t]\n","\n","          #if pd.isnull(e_sum):\n","            #print(psd_half)\n","            #print(emg_frame)\n","            \n","          meanfreq_idx = e_sum#/len(psd_half)\n","          meanfreq = (meanfreq_idx*100)/len(psd_half)          \n","          #if (pd.isnull(meanfreq)):\n","          #  print(\"{} {} {}\".format(abs_fft, log_abs_fft, log_abs_fft[128]))\n","          \n","          e_sum = 0\n","          e_half = 1/2\n","          global_t =0\n","          \n","          for t in range (0,len(psd_half),1):\n","            e_sum = e_sum + e_i[t]\n","            if e_sum >= e_half:\n","              global_t = t\n","              break\n","              \n","          medfreq_idx = global_t-1\n","          medfreq = (medfreq_idx*100)/len(psd_half)\n","          result[index].append(meanfreq)\n","          result[index].append(medfreq)          \n","          index = index + 1\n","    \n","    np.where(result=='[', '', result)\n","    np.where(result==']', '', result)\n","    np.savetxt(path + str('Features_{}.csv'.format(exp)), result, delimiter=\",\", fmt='%s')\n","    print(\"Total Features Features_{} ={}\".format(exp, index))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1668233293729,"user":{"displayName":"Estrella Designer","userId":"13292887714158322572"},"user_tz":-330},"id":"hrbGihRr8Ne8","outputId":"ebb03866-240f-4798-ec7a-5a334f1281b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["60\n","['1T', '2I', '3M', '4R', '5L']\n"]}],"source":["print(index)\n","print(fingers)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"executionInfo":{"elapsed":1172,"status":"ok","timestamp":1668233294894,"user":{"displayName":"Estrella Designer","userId":"13292887714158322572"},"user_tz":-330},"id":"lCz4NPZBpGD9","outputId":"8cc47623-c6ee-4270-bf53-51f1b917e8a4"},"outputs":[],"source":["from numpy import random\n","import numpy as np\n","import pandas as pd\n","from sklearn.manifold import TSNE\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","import seaborn as sns\n","fingers=['3M', '4R']\n","sampleData = False;\n","if sampleData:\n","  X1 = random.randint(-10,0, size=[500,2])\n","  X2 = random.randint(0,10, size=[500,2])\n","  X = np.concatenate((X1, X2))\n","  Y1 =[0]*500\n","  Y2 =[1]*500\n","  Ytrain_Plot = np.concatenate((Y1, Y2))\n","  palette = sns.color_palette(\"bright\", 2)\n","  df = pd.DataFrame(X,columns=[0,1])\n","else :\n","  features = []\n","  featuresY = []\n","  Xtrain_Plot = []\n","  Ytrain_Plot = []  \n","  for exp in fingers:\n","    fea = pandas.read_csv(path + 'Features_{}.csv'.format(exp), header=None)\n","    #fea_dropna = fea.dropna()#\n","    fea_dropna =  fea.iloc[:,0:5].dropna()#fea.iloc[0:400,0:5].dropna()\n","    features.append(fea_dropna)\n","    \n","    #print(fea_dropna[0:5])\n","    index = int(exp[0])\n","    featuresY.append([index]*len(fea_dropna))\n","    \n","  Xtrain_Plot = np.concatenate(features)\n","  Ytrain_Plot = np.concatenate(featuresY)\n","  palette = sns.color_palette(\"bright\", len(fingers))\n","  df = pd.DataFrame(Xtrain_Plot)\n","df_subset = df #df.loc[N,:].copy()\n","data_subset = df_subset.values \n","#perplexity 30 to 50\n","tsne = TSNE(n_components=2, verbose=1, perplexity=99, n_iter=750)\n","tsne_results = tsne.fit_transform(data_subset)\n","df_subset['tsne-2d-one'] = tsne_results[:,0]\n","df_subset['tsne-2d-two'] = tsne_results[:,1]\n","#print(X_Train.shape)\n","\n","#ax2 = plt.subplot(1, 3, 2)\n","sns.scatterplot(\n","    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n","    hue = Ytrain_Plot,\n","    palette=palette,\n","    data=df_subset,\n","    legend=\"full\",\n","    alpha=0.3,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1668233302849,"user":{"displayName":"Estrella Designer","userId":"13292887714158322572"},"user_tz":-330},"id":"l88F1dKxw9qG","outputId":"8be157bc-f6c1-4b84-e50f-3535249db276"},"outputs":[],"source":["print(fea.iloc[:,5:])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":631,"status":"ok","timestamp":1668233303465,"user":{"displayName":"Estrella Designer","userId":"13292887714158322572"},"user_tz":-330},"id":"O-irRVsDZcY5","outputId":"b0c87e68-93c0-4813-b2d0-4908106b66f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train (108, 5),(108,), Validation (8, 5),(8,), Test (4, 5),(4,)\n","Squeeze for IP Channel (108, 5), (4, 5), (8, 5)\n","Train Accuracy98.14814814814815\n","Test Accuracy25.0\n","Validation Accuracy50.0\n"]}],"source":["#print(\"Train {},{}, Validation {},{}, Test {},{}\".format(X_Train.shape, Y_Train.shape, X_Val.shape, Y_Val.shape,  X_Test.shape, Y_Test.shape,))\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.model_selection import cross_val_score, cross_val_predict\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import confusion_matrix  \n","from sklearn.metrics import accuracy_score\n","\n","tensorX = Xtrain_Plot\n","tensorY  = Ytrain_Plot\n","#X_Train, Xfor_test, Y_Train, Yfor_test = train_test_split(tensorX, tensorY, test_size=0.3, random_state=42)\n","X_Train, Xfor_test, Y_Train, Yfor_test = train_test_split(tensorX, tensorY, test_size=0.1, random_state=42)\n","X_Test, X_Val, Y_Test, Y_Val = train_test_split(Xfor_test, Yfor_test, test_size=(2/3), random_state=42)\n","print(\"Train {},{}, Validation {},{}, Test {},{}\".format(X_Train.shape, Y_Train.shape, X_Val.shape, Y_Val.shape,  X_Test.shape, Y_Test.shape,))\n","\n","#Xfor_test = Xfor_test.unsqueeze_(1)\n","#X_train = X_train.unsqueeze_(1)\n","#X_test = X_test.unsqueeze_(1)\n","X_Val = np.reshape(X_Val, (X_Val.shape[0], -1))\n","print(\"Squeeze for IP Channel {}, {}, {}\".format(X_Train.shape, X_Test.shape, X_Val.shape))\n","\n","sc = StandardScaler()  \n","X_train = sc.fit_transform(X_Train)  \n","X_val = sc.transform(X_Val)  \n","X_test = sc.transform(X_Test) \n","lda = LDA(n_components=len(fingers)-1)  \n","X_trainlda = lda.fit_transform(X_train, Y_Train)  \n","#print('#class={} {} {}'.format(len(fingers), X_train.shape, X_trainlda.shape))\n","X_test = lda.transform(X_test)  \n","X_val = lda.transform(X_val)  \n","\n","classifier = RandomForestClassifier(max_depth=10, random_state=0)\n","classifier.fit(X_trainlda, Y_Train)  \n","\n","y_pred = classifier.predict(X_trainlda)  \n","print('Train Accuracy' + str(accuracy_score(Y_Train, y_pred)*100)) \n","\n","y_pred = classifier.predict(X_test)  \n","print('Test Accuracy' + str(accuracy_score(Y_Test, y_pred)*100)) \n","\n","#classifier = RandomForestClassifier(max_depth=100, random_state=0)\n","#classifier.fit(X_train, Y_train)  \n","y_pred = classifier.predict(X_val)  \n","print('Validation Accuracy' + str(accuracy_score(Y_Val, y_pred)*100)) \n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM5ljTZa/Se0skLfYNVpW3q","collapsed_sections":[],"provenance":[{"file_id":"1pbozFgkVh_9ydvK9m4F4azGD12PMx0jL","timestamp":1668233337937},{"file_id":"1rvwIKmMsCkQxlFTXJzIp5lWITmYnRVYZ","timestamp":1665753312690},{"file_id":"1WcXWc4r6WjbDn79FBLpR4DRNiJGITiXX","timestamp":1664607602133}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
